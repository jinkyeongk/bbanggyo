import os

from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage
from chromadb import PersistentClient

from dotenv import load_dotenv


load_dotenv()

class AIModel:
    
    # embedding_function = OpenAIEmbeddings()
    chroma_store = Chroma(
        embedding_function=OpenAIEmbeddings(),
        persist_directory="chroma_db",  # ê¸°ì¡´ ì €ì¥ëœ Chroma DB ê²½ë¡œ
        collection_name="bakery_vector_store"  # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì´ë¦„
    )

    client = PersistentClient(path="./chroma_db") 

    collection = client.get_collection("bakery_vector_store")  # ì˜¬ë°”ë¥¸ ì»¬ë ‰ì…˜ ì´ë¦„ìœ¼ë¡œ ë³€ê²½
    #print(collection.count())  # ì €ì¥ëœ ë²¡í„° ê°œìˆ˜ ì¶œë ¥

    docs = collection.get()  # ì»¬ë ‰ì…˜ì˜ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    #print(f"ì €ì¥ëœ ë²¡í„° ê°œìˆ˜: {len(docs['ids'])}")
    #print(docs)  # ì €ì¥ëœ ë°ì´í„° ë‚´ìš© í™•ì¸
    
    def __init__(self, model_name="gpt-4o-mini", model_provider="openai"):
        # âœ… LangGraphì™€ LangChainì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ ì´ˆê¸°í™”
        self.model = init_chat_model(model_name, model_provider=model_provider)
        self.llm = ChatOpenAI(model_name=model_name)

        # âœ… LangChainìš© Prompt ì„¤ì •
        self.prompt_template = ChatPromptTemplate.from_messages(
            [
                ("system", "You are a helpful assistant. Answer all questions to the best of your ability in {language}."),
                MessagesPlaceholder(variable_name="history"),
                ("human", "{question}"),
            ]
        )

        # âœ… LangGraphëŠ” MemorySaver ì‚¬ìš© (SQLiteSaver ì œê±°)
        self.memory = MemorySaver()

        # âœ… SQLite ê¸°ë°˜ ëŒ€í™” ê¸°ë¡ ì €ì¥
        self.chat_message_history = SQLChatMessageHistory(
            session_id="test_session_id", connection_string="sqlite:///sqlite.db"
        )

        # âœ… LangGraph ì›Œí¬í”Œë¡œìš° ì„¤ì •
        self.workflow = self._build_workflow()
        self.app = self.workflow.compile(checkpointer=self.memory)

        # âœ… LangChainì˜ `RunnableWithMessageHistory`ë¡œ RAG ì ìš© ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
        self.chain = self.prompt_template | self.llm  # |ë¥¼ í†µí•´ prompt_templateê³¼ llmì„ ì—°ê²°
        self.chain_with_history = RunnableWithMessageHistory(
            self.chain,
            lambda session_id: SQLChatMessageHistory(session_id=session_id, connection_string="sqlite:///sqlite.db"),
            input_messages_key="question",
            history_messages_key="history",
        )
        
    def request(personality_query):

        # 2. Chroma ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ì‚¬ìš©ì ì„±ê²©ê³¼ ìœ ì‚¬í•œ ë¹µì§‘ ë¬¸ì„œë¥¼ ê²€ìƒ‰ (ì˜ˆ: ìƒìœ„ 3ê°œ)
        similar_docs = chroma_store.similarity_search(personality_query, k=3)
        print("íŒêµì˜ ë¹µì§‘ì„ ì°¾ì•„ë‹¤ë‹ˆê³  ìˆìŠµë‹ˆë‹¤....")

        # 3. ì¶”ì²œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±  
        #    - í›„ë³´ ë¹µì§‘ë“¤ì˜ ì •ë³´ë¥¼ ë‚˜ì—´í•˜ê³ , ì¬ë¯¸ìˆëŠ” ì¶”ì²œê³¼ ì¶”ì²œ ì´ìœ ë¥¼ ìš”ì²­í•˜ëŠ” í˜•íƒœë¡œ êµ¬ì„±
        recommendation_prompt = f"ì‚¬ìš©ìì˜ ì„±ê²©: {personality_query}\n\n"
        recommendation_prompt += "ë‹¤ìŒ ë¹µì§‘ í›„ë³´ë“¤ ì¤‘ì—ì„œ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ì–´ìš¸ë¦¬ëŠ” ì„œë¡œ ë‹¤ë¥¸ ë¹µì§‘ì„ ì„¸ ê°œ ì¶”ì²œí•´ì¤˜.\n"
        recommendation_prompt += "ë°˜ë“œì‹œ ì„œë¡œ ë‹¤ë¥¸ ë¹µì§‘ì´ì–´ì•¼ í•˜ê³ , ë°˜ë“œì‹œ ë¬¸ì„œì— ìˆëŠ” ë¹µì§‘ì´ì–´ì•¼ í•´."

        for doc in similar_docs:
            recommendation_prompt += f"- {doc.page_content}\n"
        recommendation_prompt += "\nì„¤ëª…ì€ í•„ìš”ì—†ê³  ë¹µì§‘ ì´ë¦„ì´ë‘ ë³„ì  ì•Œë ¤ì¤˜. ì–‘ì‹ì€ ì œëª© \n ì´ì  : nn ë§› : nn ê°€ê²© : nn ê³ ê°ì„œë¹„ìŠ¤ : nn"

        # 4. ChatGPT APIí˜¸ì¶œ
        llm = ChatOpenAI(temperature=0.7)
        recommendation = llm.invoke([HumanMessage(content=recommendation_prompt)])
        print("íŒêµì˜ ë¹µì§‘ì„ ì°¾ì•„ë‹¤ë‹ˆê³  ìˆìŠµë‹ˆë‹¤....ğŸ’¨")

        print("ì¶”ì²œ ê²°ê³¼:")
        print(recommendation.content)

        explanation_prompt = (
            f"ìœ„ì˜ ì¶”ì²œ ê²°ê³¼ì— ëŒ€í•´, í•´ë‹¹ ë¹µì§‘ì´ ë‚´ê°€ ì…ë ¥í•œ ì„±ê²©ê³¼ ë¬´ìŠ¨ ê´€ê³„ê°€ ìˆëŠ”ì§€ í•œ ì¤„ë¡œ ì„¤ëª…í•´ì¤˜.\n\n"
            f"ì‚¬ìš©ì ì„±ê²©: {personality_query}\n\n"
            f"ì¶”ì²œëœ ë¹µì§‘ ì •ë³´: {similar_docs[0].page_content}"
        )
        explanation = llm.invoke([HumanMessage(content=explanation_prompt)])

        print("\nì¶”ì²œ ì´ìœ :")
        print(explanation.content)